{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 970,
     "status": "ok",
     "timestamp": 1619296686391,
     "user": {
      "displayName": "Vladimir Krokhmal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjcSfoo-ppCTl7n283tjLGh1X7jELJ6uJ7LCEYY=s64",
      "userId": "01171303794857667564"
     },
     "user_tz": 240
    },
    "id": "18rPiunHKjrb",
    "outputId": "ea1bee75-33e6-4d32-81d4-4c90447f1d59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Code to work in Google Colab\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1127,
     "status": "ok",
     "timestamp": 1619296686584,
     "user": {
      "displayName": "Vladimir Krokhmal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjcSfoo-ppCTl7n283tjLGh1X7jELJ6uJ7LCEYY=s64",
      "userId": "01171303794857667564"
     },
     "user_tz": 240
    },
    "id": "jC8Hez0LunFe"
   },
   "outputs": [],
   "source": [
    "# Leave this\n",
    "num_epochs = 10\n",
    "\n",
    "# TUNE THESE to achieve maximum performance\n",
    "batch_size = 16\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1107,
     "status": "ok",
     "timestamp": 1619296686588,
     "user": {
      "displayName": "Vladimir Krokhmal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjcSfoo-ppCTl7n283tjLGh1X7jELJ6uJ7LCEYY=s64",
      "userId": "01171303794857667564"
     },
     "user_tz": 240
    },
    "id": "YBx0hhxgLMoM",
    "outputId": "11bcf2cb-aed2-4848-e4bf-0f2dcee046e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metadata.json', 'Image.zip', '545 Project Ideas.gdoc', 'data_scene_flow', 'Copy of Data_Loading.ipynb', '.ipynb_checkpoints', 'Image.zip (Unzipped Files)', 'Images', 'Untitled Diagram.drawio', 'Weather', 'Extra_Weather_Data', 'More_Weather_Data_60k', 'DataSplit.ipynb', 'Unet + triplet loss.ipynb', 'Data_Loading.ipynb', 'saved_model', 'Untitled', '__pycache__', 'Test version(Yuanbin)-UNet Triplet loss.ipynb', 'JoeyVAE598.py', 'Performance', 'WeatherVAE.ipynb', 'Joey Unet and Content Loss.ipynb', 'WeatherVAE.pt', 'ExampleInterpolation.png', 'Tune parameters.ipynb', 'WeatherVAE-test (Jason).ipynb', 'newest Unet and Triplet Loss.ipynb', 'JoeyTransferLearning.ipynb', 'Baselines.ipynb']\n",
      "/content/drive/My Drive/EECS 545 Project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', 'EECS 545 Project')\n",
    "print(os.listdir(GOOGLE_DRIVE_PATH))\n",
    "\n",
    "os.chdir(GOOGLE_DRIVE_PATH)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1687,
     "status": "ok",
     "timestamp": 1619296687195,
     "user": {
      "displayName": "Vladimir Krokhmal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjcSfoo-ppCTl7n283tjLGh1X7jELJ6uJ7LCEYY=s64",
      "userId": "01171303794857667564"
     },
     "user_tz": 240
    },
    "id": "nosNfoPqLw1I"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1675,
     "status": "ok",
     "timestamp": 1619296687201,
     "user": {
      "displayName": "Vladimir Krokhmal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjcSfoo-ppCTl7n283tjLGh1X7jELJ6uJ7LCEYY=s64",
      "userId": "01171303794857667564"
     },
     "user_tz": 240
    },
    "id": "mS3fd_mqS5--"
   },
   "outputs": [],
   "source": [
    "class SmallDataLoader:\n",
    "  def __init__(self, BatchSize=16, TestPercent=0.1, data_loc=\"Weather\", img_size=224, dev=\"cuda\"):\n",
    "    self.train_names = []\n",
    "    self.train_labels = []\n",
    "    self.val_names = []\n",
    "    self.val_labels = []\n",
    "    self.test_names = []\n",
    "    self.test_labels = []\n",
    "\n",
    "    self.label_keys = {0: \"cloudy\", 1: \"foggy\", 2: \"rain\", 3: \"snow\", 4: \"sunny\"}\n",
    "    self.data_loc = os.path.join(os.getcwd(), data_loc)\n",
    "    self.batch_size = BatchSize\n",
    "    self.img_size = img_size\n",
    "    self.dev=dev\n",
    "\n",
    "    data_types = [\"cloudy\", \"foggy\", \"rain\", \"snow\", \"sunny\"]\n",
    "    splits = [\"Train\", \"Val\", \"Test\"]\n",
    "    for split in splits:\n",
    "      for i in range(5):\n",
    "        dtype = self.label_keys[i]\n",
    "        type_loc = os.path.join(data_loc, split, dtype)\n",
    "        files = os.listdir(type_loc)\n",
    "\n",
    "        if split == \"Train\":\n",
    "          self.train_labels += len(files) * [i]\n",
    "          self.train_names += files\n",
    "        elif split == \"Val\":\n",
    "          self.val_labels += len(files) * [i]\n",
    "          self.val_names += files\n",
    "        elif split == \"Test\":\n",
    "          self.test_labels += len(files) * [i]\n",
    "          self.test_names += files\n",
    "\n",
    "    # Shuffle data first\n",
    "    self.N_train = len(self.train_names) - len(self.train_names) % self.batch_size\n",
    "    self.N_val = len(self.val_names) - len(self.val_names) % self.batch_size\n",
    "    self.N_test = len(self.test_names) - len(self.test_names) % self.batch_size\n",
    "    self.shuffle_train()\n",
    "\n",
    "    self.iter_no = 0\n",
    "    self.val_no = 0\n",
    "\n",
    "    self.transform_dict = {\n",
    "        \"Train\": transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
    "        transforms.GaussianBlur(5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]),\n",
    "        \"Val\": transforms.Compose([\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    }\n",
    "\n",
    "  # index into file names, labels\n",
    "  def get_ind(self, index, dset=\"Train\"):\n",
    "    if dset == \"Train\":\n",
    "      fname = self.train_names[index]\n",
    "      label = self.train_labels[index]\n",
    "    elif dset == \"Val\":\n",
    "      fname = self.val_names[index]\n",
    "      label = self.val_labels[index]\n",
    "\n",
    "    label_name = self.label_keys[label]\n",
    "    img_loc = os.path.join(self.data_loc, dset, label_name, fname)\n",
    "    input_image = Image.open(img_loc).convert('RGB')\n",
    "    input_tensor = self.transform_dict[dset](input_image)\n",
    "\n",
    "    return input_tensor, label\n",
    "\n",
    "  # For training\n",
    "  def get_batch(self):\n",
    "    # End of Epoch\n",
    "    if self.iter_no + self.batch_size >= self.N_train:\n",
    "      self.iter_no = 0\n",
    "      return \"EOE\", None\n",
    "\n",
    "    batch_img = torch.zeros((self.batch_size, 3, self.img_size, self.img_size), device=self.dev)\n",
    "    batch_lab = torch.zeros((self.batch_size), device=self.dev, dtype=torch.long)\n",
    "    for i in range(self.batch_size):\n",
    "      input_tensor, label = self.get_ind(self.iter_no + i)\n",
    "      batch_img[i] = input_tensor\n",
    "      batch_lab[i] = label\n",
    "    self.iter_no += self.batch_size\n",
    "    return batch_img, batch_lab\n",
    "\n",
    "  def get_val(self):\n",
    "    if self.val_no + self.batch_size >= self.N_val:\n",
    "      self.val_no = 0\n",
    "      return \"EOE\", None\n",
    "\n",
    "    batch_img = torch.zeros((self.batch_size, 3, self.img_size, self.img_size), device=self.dev)\n",
    "    batch_lab = torch.zeros((self.batch_size), device=self.dev, dtype=torch.long)\n",
    "    for i in range(self.batch_size):\n",
    "      input_tensor, label = self.get_ind(self.val_no + i, dset=\"Val\")\n",
    "      batch_img[i] = input_tensor\n",
    "      batch_lab[i] = label\n",
    "    self.val_no += self.batch_size\n",
    "    return batch_img, batch_lab\n",
    "\n",
    "\n",
    "  def shuffle_train(self):\n",
    "    inds = np.random.choice(self.N_train, size=self.N_train, replace=False)\n",
    "    self.train_names = [self.train_names[i] for i in inds]\n",
    "    self.train_labels = [self.train_labels[i] for i in inds]\n",
    "    self.iter_no = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1657,
     "status": "ok",
     "timestamp": 1619296687203,
     "user": {
      "displayName": "Vladimir Krokhmal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjcSfoo-ppCTl7n283tjLGh1X7jELJ6uJ7LCEYY=s64",
      "userId": "01171303794857667564"
     },
     "user_tz": 240
    },
    "id": "MbEeHhByWDLo"
   },
   "outputs": [],
   "source": [
    "class BigDataLoader:\n",
    "  def __init__(self, BatchSize=16, TrainRat=0.9, ValRat=0.05, TestRat=0.05, file_loc=\"Weather\", data_loc=\"Images/Image\", img_size=224, dev=\"cuda\"):\n",
    "    self.train_names = []\n",
    "    self.train_labels = []\n",
    "    self.val_names = []\n",
    "    self.val_labels = []\n",
    "    self.test_names = []\n",
    "    self.test_labels = []\n",
    "\n",
    "    self.label_keys = {0: \"cloudy\", 1: \"foggy\", 2: \"rain\", 3: \"snow\", 4: \"sunny\"}\n",
    "    self.data_loc = os.path.join(os.getcwd(), data_loc)\n",
    "    self.file_loc = os.path.join(os.getcwd(), file_loc)\n",
    "    self.batch_size = BatchSize\n",
    "    self.img_size = img_size\n",
    "    self.dev=dev\n",
    "\n",
    "    # Get file names for weather types\n",
    "    for w_ind in self.label_keys.keys():\n",
    "      w_type = self.label_keys[w_ind]\n",
    "      f = open(os.path.join(file_loc, w_type + \".txt\"), 'r')\n",
    "      lines = [line.strip() for line in f.readlines()]\n",
    "      f.close()\n",
    "      # Create a list of keys, files\n",
    "      N = len(lines)\n",
    "      self.train_names += lines[:int(N*TrainRat)]\n",
    "      self.train_labels += [w_ind] * len(lines[:int(N*TrainRat)])\n",
    "\n",
    "      self.val_names += lines[int(N*TrainRat):int(N*(TrainRat + ValRat))]\n",
    "      self.val_labels += [w_ind] * len(lines[int(N*TrainRat):int(N*(TrainRat + ValRat))])\n",
    "\n",
    "      self.test_names += lines[int(N*(TrainRat + ValRat)):]\n",
    "      self.test_labels += [w_ind] * len(lines[int(N*(TrainRat + ValRat)):])\n",
    "\n",
    "    # Shuffle data first\n",
    "    self.N_train = len(self.train_names) - len(self.train_names) % self.batch_size\n",
    "    self.N_val = len(self.val_names) - len(self.val_names) % self.batch_size\n",
    "    self.N_test = len(self.test_names) - len(self.test_names) % self.batch_size\n",
    "    self.shuffle_train()\n",
    "\n",
    "    self.iter_no = 0\n",
    "    self.val_no = 0\n",
    "\n",
    "    self.transform_dict = {\n",
    "        \"Train\": transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
    "        transforms.GaussianBlur(5),\n",
    "         transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]),\n",
    "        \"Val\": transforms.Compose([\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    }\n",
    "\n",
    "  # index into file names, labels\n",
    "  def get_ind(self, index, dset=\"Train\"):\n",
    "    if dset == \"Train\":\n",
    "      fname = self.train_names[index]\n",
    "      label = self.train_labels[index]\n",
    "    elif dset == \"Val\":\n",
    "      fname = self.val_names[index]\n",
    "      label = self.val_labels[index]\n",
    "\n",
    "    label_name = self.label_keys[label]\n",
    "    img_loc = os.path.join(self.data_loc, label_name, fname)\n",
    "    input_image = Image.open(img_loc)\n",
    "    input_tensor = self.transform_dict[dset](input_image)\n",
    "\n",
    "    return input_tensor, label\n",
    "\n",
    "  # For training\n",
    "  def get_batch(self):\n",
    "    # End of Epoch\n",
    "    if self.iter_no + self.batch_size >= self.N_train:\n",
    "      self.iter_no = 0\n",
    "      return \"EOE\", None\n",
    "\n",
    "    batch_img = torch.zeros((self.batch_size, 3, self.img_size, self.img_size), device=self.dev)\n",
    "    batch_lab = torch.zeros((self.batch_size), device=self.dev, dtype=torch.long)\n",
    "    for i in range(self.batch_size):\n",
    "      input_tensor, label = self.get_ind(self.iter_no + i)\n",
    "      batch_img[i] = input_tensor\n",
    "      batch_lab[i] = label\n",
    "    self.iter_no += self.batch_size\n",
    "    return batch_img, batch_lab\n",
    "\n",
    "  def get_val(self):\n",
    "    if self.val_no + self.batch_size >= self.N_val:\n",
    "      self.val_no = 0\n",
    "      return \"EOE\", None\n",
    "\n",
    "    batch_img = torch.zeros((self.batch_size, 3, self.img_size, self.img_size), device=self.dev)\n",
    "    batch_lab = torch.zeros((self.batch_size), device=self.dev, dtype=torch.long)\n",
    "    for i in range(self.batch_size):\n",
    "      input_tensor, label = self.get_ind(self.val_no + i, dset=\"Val\")\n",
    "      batch_img[i] = input_tensor\n",
    "      batch_lab[i] = label\n",
    "    self.val_no += self.batch_size\n",
    "    return batch_img, batch_lab\n",
    "\n",
    "\n",
    "  def shuffle_train(self):\n",
    "    inds = np.random.choice(self.N_train, size=self.N_train, replace=False)\n",
    "    self.train_names = [self.train_names[i] for i in inds]\n",
    "    self.train_labels = [self.train_labels[i] for i in inds]\n",
    "    self.iter_no = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1637,
     "status": "ok",
     "timestamp": 1619296687206,
     "user": {
      "displayName": "Vladimir Krokhmal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjcSfoo-ppCTl7n283tjLGh1X7jELJ6uJ7LCEYY=s64",
      "userId": "01171303794857667564"
     },
     "user_tz": 240
    },
    "id": "6Ynd2x6WWomu",
    "outputId": "87481eea-89c4-4c10-df7b-5cfbb465df0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2144 256 384\n"
     ]
    }
   ],
   "source": [
    "dl = SmallDataLoader()\n",
    "dl.shuffle_train()\n",
    "print(dl.N_train, dl.N_val, dl.N_test)\n",
    "\n",
    "# dl = BigDataLoader()\n",
    "# dl.shuffle_train()\n",
    "# print(dl.N_train, dl.N_val, dl.N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5583,
     "status": "ok",
     "timestamp": 1619296691192,
     "user": {
      "displayName": "Vladimir Krokhmal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjcSfoo-ppCTl7n283tjLGh1X7jELJ6uJ7LCEYY=s64",
      "userId": "01171303794857667564"
     },
     "user_tz": 240
    },
    "id": "MHUPlyqD4JuX",
    "outputId": "0b76ef64-0966-4c25-e1f8-8c8c8e496971"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8283, 1.2342, 0.2331, 0.2383, 0.1288], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "model = torch.hub.load('pytorch/vision:v0.9.0', 'resnet18', pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "num_classes = len(dl.label_keys)\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "model.to(dl.dev)\n",
    "\n",
    "batch_im, batch_lab = dl.get_batch()\n",
    "with torch.no_grad():\n",
    "    output = model(batch_im)\n",
    "\n",
    "# Tensor of shape 5\n",
    "print(output[0])\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 5555,
     "status": "ok",
     "timestamp": 1619296691195,
     "user": {
      "displayName": "Vladimir Krokhmal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjcSfoo-ppCTl7n283tjLGh1X7jELJ6uJ7LCEYY=s64",
      "userId": "01171303794857667564"
     },
     "user_tz": 240
    },
    "id": "kd2NMuY-8Rk9"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, data_loader, num_epochs=10):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    train_hist = []\n",
    "    val_hist = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            data_loader.shuffle_train()\n",
    "            while True:\n",
    "                if phase == \"train\":\n",
    "                  inputs, labels = data_loader.get_batch()\n",
    "                else:\n",
    "                  inputs, labels = data_loader.get_val()\n",
    "                # End of epoch\n",
    "                if inputs == \"EOE\":\n",
    "                  break\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            if phase == \"train\":\n",
    "              epoch_loss = running_loss / data_loader.N_train\n",
    "              epoch_acc = running_corrects / data_loader.N_train\n",
    "            else:\n",
    "              epoch_loss = running_loss / data_loader.N_val\n",
    "              epoch_acc = running_corrects / data_loader.N_val\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            if phase == \"train\":\n",
    "              train_hist.append(epoch_acc)\n",
    "            else:\n",
    "              val_hist.append(epoch_acc)\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, train_hist, val_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3224128,
     "status": "ok",
     "timestamp": 1619299909794,
     "user": {
      "displayName": "Vladimir Krokhmal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjcSfoo-ppCTl7n283tjLGh1X7jELJ6uJ7LCEYY=s64",
      "userId": "01171303794857667564"
     },
     "user_tz": 240
    },
    "id": "QIRfLCSF6MB5",
    "outputId": "d2cd064a-f2ee-4ce5-f61a-5b164c3a56a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 1.6768 Acc: 0.3568\n",
      "val Loss: 1.4199 Acc: 0.3594\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 1.3411 Acc: 0.4398\n",
      "val Loss: 1.3380 Acc: 0.3828\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 1.2719 Acc: 0.4729\n",
      "val Loss: 1.3363 Acc: 0.3555\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 1.2827 Acc: 0.4757\n",
      "val Loss: 1.3313 Acc: 0.3594\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 1.2864 Acc: 0.4734\n",
      "val Loss: 1.3346 Acc: 0.3555\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 1.2773 Acc: 0.4851\n",
      "val Loss: 1.3374 Acc: 0.3633\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 1.2888 Acc: 0.4757\n",
      "val Loss: 1.3330 Acc: 0.3555\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 1.2687 Acc: 0.4972\n",
      "val Loss: 1.3349 Acc: 0.3594\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 1.2878 Acc: 0.4669\n",
      "val Loss: 1.3351 Acc: 0.3516\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 1.2753 Acc: 0.4711\n",
      "val Loss: 1.3309 Acc: 0.3555\n",
      "Training complete in 10m 50s\n",
      "Best val Acc: 0.382812\n",
      "vgg11_bn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 4.3829 Acc: 0.2341\n",
      "val Loss: 1.5580 Acc: 0.2344\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 1.5608 Acc: 0.2519\n",
      "val Loss: 1.5019 Acc: 0.2930\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 1.5445 Acc: 0.2407\n",
      "val Loss: 1.4981 Acc: 0.2773\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 1.5463 Acc: 0.2645\n",
      "val Loss: 1.4953 Acc: 0.2812\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 1.5456 Acc: 0.2668\n",
      "val Loss: 1.4931 Acc: 0.2695\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 1.5431 Acc: 0.2696\n",
      "val Loss: 1.5001 Acc: 0.2773\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 1.5436 Acc: 0.2691\n",
      "val Loss: 1.5006 Acc: 0.2773\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 1.5405 Acc: 0.2663\n",
      "val Loss: 1.5009 Acc: 0.2695\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 1.5440 Acc: 0.2607\n",
      "val Loss: 1.4975 Acc: 0.2969\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 1.5442 Acc: 0.2561\n",
      "val Loss: 1.5034 Acc: 0.2891\n",
      "Training complete in 10m 50s\n",
      "Best val Acc: 0.296875\n",
      "vgg19_bn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 5.5503 Acc: 0.2332\n",
      "val Loss: 1.6238 Acc: 0.1484\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 1.6125 Acc: 0.2575\n",
      "val Loss: 1.5157 Acc: 0.2578\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 1.5479 Acc: 0.2542\n",
      "val Loss: 1.5104 Acc: 0.2930\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 1.5431 Acc: 0.2868\n",
      "val Loss: 1.5142 Acc: 0.2773\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 1.5461 Acc: 0.2547\n",
      "val Loss: 1.5205 Acc: 0.2383\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 1.5394 Acc: 0.2943\n",
      "val Loss: 1.5165 Acc: 0.2500\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 1.5373 Acc: 0.2771\n",
      "val Loss: 1.5183 Acc: 0.2383\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 1.5292 Acc: 0.2607\n",
      "val Loss: 1.5113 Acc: 0.2891\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 1.5409 Acc: 0.2733\n",
      "val Loss: 1.5121 Acc: 0.2852\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 1.5362 Acc: 0.2817\n",
      "val Loss: 1.5153 Acc: 0.3359\n",
      "Training complete in 14m 49s\n",
      "Best val Acc: 0.335938\n",
      "resnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 1.5202 Acc: 0.3652\n",
      "val Loss: 1.3276 Acc: 0.3750\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 1.3339 Acc: 0.4454\n",
      "val Loss: 1.3601 Acc: 0.3281\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 1.2737 Acc: 0.4627\n",
      "val Loss: 1.3391 Acc: 0.3359\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 1.2793 Acc: 0.4543\n",
      "val Loss: 1.3401 Acc: 0.3438\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 1.2862 Acc: 0.4669\n",
      "val Loss: 1.3175 Acc: 0.3516\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 1.2730 Acc: 0.4650\n",
      "val Loss: 1.3233 Acc: 0.3516\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 1.2838 Acc: 0.4632\n",
      "val Loss: 1.3405 Acc: 0.3438\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 1.2618 Acc: 0.4729\n",
      "val Loss: 1.3236 Acc: 0.3438\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 1.2764 Acc: 0.4608\n",
      "val Loss: 1.3638 Acc: 0.3320\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 1.2465 Acc: 0.4683\n",
      "val Loss: 1.3277 Acc: 0.3477\n",
      "Training complete in 8m 23s\n",
      "Best val Acc: 0.375000\n",
      "resnet34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 1.5823 Acc: 0.3316\n",
      "val Loss: 1.5783 Acc: 0.3516\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 1.3936 Acc: 0.4193\n",
      "val Loss: 1.3263 Acc: 0.3750\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 1.3535 Acc: 0.4408\n",
      "val Loss: 1.3289 Acc: 0.3789\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 1.3471 Acc: 0.4375\n",
      "val Loss: 1.3181 Acc: 0.3750\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 1.3487 Acc: 0.4338\n",
      "val Loss: 1.3249 Acc: 0.3633\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 1.3496 Acc: 0.4398\n",
      "val Loss: 1.3309 Acc: 0.3672\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 1.3527 Acc: 0.4310\n",
      "val Loss: 1.3316 Acc: 0.3711\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 1.3464 Acc: 0.4370\n",
      "val Loss: 1.3307 Acc: 0.3594\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 1.3546 Acc: 0.4422\n",
      "val Loss: 1.3212 Acc: 0.3672\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 1.3468 Acc: 0.4333\n",
      "val Loss: 1.3203 Acc: 0.3633\n",
      "Training complete in 8m 42s\n",
      "Best val Acc: 0.378906\n"
     ]
    }
   ],
   "source": [
    "# Without transfer learning\n",
    "dl = SmallDataLoader(BatchSize=batch_size)\n",
    "\n",
    "models = {}\n",
    "train_hist = {}\n",
    "val_hist = {}\n",
    "num_classes = len(dl.label_keys)\n",
    "\n",
    "for model_name in [\"resnet50\", \"vgg11_bn\", \"vgg19_bn\", \"resnet18\", \"resnet34\"]:\n",
    "  print(model_name)\n",
    "  model = torch.hub.load('pytorch/vision:v0.9.0', model_name, pretrained=False)\n",
    "  if model_name[:3] == \"vgg\":\n",
    "    num_ftrs = model.classifier[6].in_features\n",
    "    model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "  else:\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "  model.to(dl.dev)\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  # Observe that all parameters are being optimized\n",
    "  optimizer_ft = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "  # Decay LR by a factor of 0.1 every 7 epochs\n",
    "  exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=1, gamma=0.1)\n",
    "\n",
    "  models[model_name], train_hist[model_name], val_hist[model_name] = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, dl, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3224108,
     "status": "ok",
     "timestamp": 1619299909800,
     "user": {
      "displayName": "Vladimir Krokhmal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjcSfoo-ppCTl7n283tjLGh1X7jELJ6uJ7LCEYY=s64",
      "userId": "01171303794857667564"
     },
     "user_tz": 240
    },
    "id": "jldKYALq0FL6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3224087,
     "status": "ok",
     "timestamp": 1619299909803,
     "user": {
      "displayName": "Vladimir Krokhmal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjcSfoo-ppCTl7n283tjLGh1X7jELJ6uJ7LCEYY=s64",
      "userId": "01171303794857667564"
     },
     "user_tz": 240
    },
    "id": "2NC1wwq8DaFY",
    "outputId": "273752f5-ca60-4dc3-e1d4-33e87bd94731"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not transfer learning\n",
      "resnet50 tensor(0.3555, device='cuda:0')\n",
      "vgg11_bn tensor(0.2891, device='cuda:0')\n",
      "vgg19_bn tensor(0.3359, device='cuda:0')\n",
      "resnet18 tensor(0.3477, device='cuda:0')\n",
      "resnet34 tensor(0.3633, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Not transfer learning\")\n",
    "for model_name in train_hist.keys():\n",
    "  print(model_name, val_hist[model_name][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5612733,
     "status": "ok",
     "timestamp": 1619302298475,
     "user": {
      "displayName": "Vladimir Krokhmal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjcSfoo-ppCTl7n283tjLGh1X7jELJ6uJ7LCEYY=s64",
      "userId": "01171303794857667564"
     },
     "user_tz": 240
    },
    "id": "kSPkypzxDesR",
    "outputId": "2710ebbb-601c-4bfe-9f72-8ce903212063"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 1.1949 Acc: 0.5182\n",
      "val Loss: 1.2537 Acc: 0.4102\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.9198 Acc: 0.6549\n",
      "val Loss: 1.1212 Acc: 0.4727\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.8960 Acc: 0.6712\n",
      "val Loss: 1.1447 Acc: 0.4570\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.8906 Acc: 0.6758\n",
      "val Loss: 1.1526 Acc: 0.4453\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.8924 Acc: 0.6660\n",
      "val Loss: 1.1543 Acc: 0.4688\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.8874 Acc: 0.6782\n",
      "val Loss: 1.1668 Acc: 0.4492\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.8981 Acc: 0.6665\n",
      "val Loss: 1.1548 Acc: 0.4375\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.8861 Acc: 0.6800\n",
      "val Loss: 1.1540 Acc: 0.4609\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.8743 Acc: 0.6810\n",
      "val Loss: 1.1446 Acc: 0.4492\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.8877 Acc: 0.6758\n",
      "val Loss: 1.1577 Acc: 0.4375\n",
      "Training complete in 8m 19s\n",
      "Best val Acc: 0.472656\n",
      "vgg11_bn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 1.0749 Acc: 0.5835\n",
      "val Loss: 1.2309 Acc: 0.4375\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.9218 Acc: 0.6283\n",
      "val Loss: 1.1687 Acc: 0.4688\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.8877 Acc: 0.6642\n",
      "val Loss: 1.1545 Acc: 0.4766\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.8894 Acc: 0.6446\n",
      "val Loss: 1.1627 Acc: 0.4570\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.8701 Acc: 0.6730\n",
      "val Loss: 1.1580 Acc: 0.4727\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.8723 Acc: 0.6632\n",
      "val Loss: 1.1654 Acc: 0.4570\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.8810 Acc: 0.6581\n",
      "val Loss: 1.1514 Acc: 0.4766\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.8818 Acc: 0.6572\n",
      "val Loss: 1.1755 Acc: 0.4570\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.8928 Acc: 0.6516\n",
      "val Loss: 1.1836 Acc: 0.4531\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.8603 Acc: 0.6702\n",
      "val Loss: 1.1868 Acc: 0.4609\n",
      "Training complete in 7m 55s\n",
      "Best val Acc: 0.476562\n",
      "vgg19_bn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 1.1199 Acc: 0.5480\n",
      "val Loss: 1.3095 Acc: 0.4102\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.9379 Acc: 0.6451\n",
      "val Loss: 1.3399 Acc: 0.3633\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.9237 Acc: 0.6469\n",
      "val Loss: 1.2797 Acc: 0.4023\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.9403 Acc: 0.6325\n",
      "val Loss: 1.2914 Acc: 0.4062\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.9207 Acc: 0.6488\n",
      "val Loss: 1.3484 Acc: 0.3633\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.9044 Acc: 0.6604\n",
      "val Loss: 1.2911 Acc: 0.3984\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.9047 Acc: 0.6460\n",
      "val Loss: 1.3810 Acc: 0.3477\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.9342 Acc: 0.6287\n",
      "val Loss: 1.3029 Acc: 0.3945\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.9066 Acc: 0.6493\n",
      "val Loss: 1.3080 Acc: 0.3984\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.9567 Acc: 0.6185\n",
      "val Loss: 1.3278 Acc: 0.3828\n",
      "Training complete in 8m 55s\n",
      "Best val Acc: 0.410156\n",
      "resnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 1.3098 Acc: 0.4669\n",
      "val Loss: 1.3445 Acc: 0.3320\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 1.0607 Acc: 0.5984\n",
      "val Loss: 1.3082 Acc: 0.4023\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 1.0227 Acc: 0.6292\n",
      "val Loss: 1.3316 Acc: 0.3750\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 1.0337 Acc: 0.6161\n",
      "val Loss: 1.3228 Acc: 0.3633\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 1.0436 Acc: 0.6138\n",
      "val Loss: 1.3337 Acc: 0.3555\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 1.0313 Acc: 0.6110\n",
      "val Loss: 1.3309 Acc: 0.3750\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 1.0293 Acc: 0.6227\n",
      "val Loss: 1.3154 Acc: 0.3906\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 1.0278 Acc: 0.6231\n",
      "val Loss: 1.3108 Acc: 0.3945\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 1.0300 Acc: 0.6259\n",
      "val Loss: 1.3157 Acc: 0.3906\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 1.0370 Acc: 0.6077\n",
      "val Loss: 1.3219 Acc: 0.3633\n",
      "Training complete in 7m 5s\n",
      "Best val Acc: 0.402344\n",
      "resnet34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 1.2823 Acc: 0.4711\n",
      "val Loss: 1.3939 Acc: 0.3828\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 1.0401 Acc: 0.6110\n",
      "val Loss: 1.3113 Acc: 0.3984\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 1.0010 Acc: 0.6343\n",
      "val Loss: 1.2891 Acc: 0.4102\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.9929 Acc: 0.6437\n",
      "val Loss: 1.3005 Acc: 0.4102\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 1.0000 Acc: 0.6278\n",
      "val Loss: 1.2954 Acc: 0.4258\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 1.0168 Acc: 0.6236\n",
      "val Loss: 1.2797 Acc: 0.4258\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 1.0237 Acc: 0.6189\n",
      "val Loss: 1.2939 Acc: 0.4180\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 1.0097 Acc: 0.6371\n",
      "val Loss: 1.2969 Acc: 0.3984\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 1.0032 Acc: 0.6269\n",
      "val Loss: 1.2747 Acc: 0.4375\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 1.0110 Acc: 0.6427\n",
      "val Loss: 1.2719 Acc: 0.4258\n",
      "Training complete in 7m 31s\n",
      "Best val Acc: 0.437500\n"
     ]
    }
   ],
   "source": [
    "# Using transfer learning\n",
    "dl = SmallDataLoader(BatchSize=batch_size)\n",
    "\n",
    "models = {}\n",
    "train_hist = {}\n",
    "val_hist = {}\n",
    "num_classes = len(dl.label_keys)\n",
    "\n",
    "for model_name in [\"resnet50\", \"vgg11_bn\", \"vgg19_bn\", \"resnet18\", \"resnet34\"]:\n",
    "  print(model_name)\n",
    "  model = torch.hub.load('pytorch/vision:v0.9.0', model_name, pretrained=True)\n",
    "\n",
    "  # Freeze\n",
    "  for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "  # Add fc layer\n",
    "  if model_name[:3] == \"vgg\":\n",
    "    num_ftrs = model.classifier[6].in_features\n",
    "    model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "  else:\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "  model.to(dl.dev)\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  # Observe that all parameters are being optimized\n",
    "  optimizer_ft = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "  # Decay LR by a factor of 0.1 every 7 epochs\n",
    "  exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=1, gamma=0.1)\n",
    "\n",
    "  models[model_name], train_hist[model_name], val_hist[model_name] = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, dl, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5612708,
     "status": "ok",
     "timestamp": 1619302298476,
     "user": {
      "displayName": "Vladimir Krokhmal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjcSfoo-ppCTl7n283tjLGh1X7jELJ6uJ7LCEYY=s64",
      "userId": "01171303794857667564"
     },
     "user_tz": 240
    },
    "id": "AaqlxxZk22MC",
    "outputId": "9ba4d418-b559-4c17-e53a-d6f6c4a4724b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer Learning\n",
      "resnet50 tensor(0.4375, device='cuda:0')\n",
      "vgg11_bn tensor(0.4609, device='cuda:0')\n",
      "vgg19_bn tensor(0.3828, device='cuda:0')\n",
      "resnet18 tensor(0.3633, device='cuda:0')\n",
      "resnet34 tensor(0.4258, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Transfer Learning\")\n",
    "for model_name in train_hist.keys():\n",
    "  print(model_name, val_hist[model_name][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 5612681,
     "status": "ok",
     "timestamp": 1619302298477,
     "user": {
      "displayName": "Vladimir Krokhmal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjcSfoo-ppCTl7n283tjLGh1X7jELJ6uJ7LCEYY=s64",
      "userId": "01171303794857667564"
     },
     "user_tz": 240
    },
    "id": "bUXutoGZ22zX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Baselines.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
