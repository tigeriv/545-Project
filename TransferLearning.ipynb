{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1085,
     "status": "ok",
     "timestamp": 1619291784058,
     "user": {
      "displayName": "Joseph Wilson",
      "photoUrl": "",
      "userId": "10418926994387796219"
     },
     "user_tz": 240
    },
    "id": "WcrQpl2mVyqz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import skimage.io as io\n",
    "from skimage import color\n",
    "import cv2\n",
    "from google.colab import drive\n",
    "from torchvision import datasets, models, transforms\n",
    "import copy\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "### only for reference\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1082,
     "status": "ok",
     "timestamp": 1619291784064,
     "user": {
      "displayName": "Joseph Wilson",
      "photoUrl": "",
      "userId": "10418926994387796219"
     },
     "user_tz": 240
    },
    "id": "guNyyj4LSKI6"
   },
   "outputs": [],
   "source": [
    "# Leave this\n",
    "num_epochs = 10\n",
    "\n",
    "# Tune these\n",
    "learning_rate = 3e-2\n",
    "batch_size = 8 # Note: anything above 16 might cause cuda to run out of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1079,
     "status": "ok",
     "timestamp": 1619291784066,
     "user": {
      "displayName": "Joseph Wilson",
      "photoUrl": "",
      "userId": "10418926994387796219"
     },
     "user_tz": 240
    },
    "id": "gAcMqaYbV5Ux",
    "outputId": "bbc35218-fb0f-49b8-9f24-f4d50ed4e90a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1075,
     "status": "ok",
     "timestamp": 1619291784069,
     "user": {
      "displayName": "Joseph Wilson",
      "photoUrl": "",
      "userId": "10418926994387796219"
     },
     "user_tz": 240
    },
    "id": "oqQTuULBYWqC",
    "outputId": "d900e8e0-7730-4b0e-bbe9-bdb0be315546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metadata.json', 'Image.zip', '545 Project Ideas.gdoc', 'data_scene_flow', 'Copy of Data_Loading.ipynb', '.ipynb_checkpoints', 'Image.zip (Unzipped Files)', 'Images', 'Untitled Diagram.drawio', 'Weather', 'Extra_Weather_Data', 'More_Weather_Data_60k', 'DataSplit.ipynb', 'Unet + triplet loss.ipynb', 'Data_Loading.ipynb', 'saved_model', 'Untitled', '__pycache__', 'Test version(Yuanbin)-UNet Triplet loss.ipynb', 'JoeyVAE598.py', 'Performance', 'WeatherVAE.ipynb', 'Joey Unet and Content Loss.ipynb', 'WeatherVAE.pt', 'ExampleInterpolation.png', 'JoeyTransferLearning.ipynb', 'Tune parameters.ipynb', 'Baselines.ipynb', 'WeatherVAE-test (Jason).ipynb', 'newest Unet and Triplet Loss.ipynb']\n",
      "/content/drive/.shortcut-targets-by-id/1YO9ukO9embmobkuEcbxl71Qpmtma6P0Q/EECS 545 Project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', 'EECS 545 Project')\n",
    "print(os.listdir(GOOGLE_DRIVE_PATH))\n",
    "\n",
    "os.chdir(GOOGLE_DRIVE_PATH)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1299,
     "status": "ok",
     "timestamp": 1619291784300,
     "user": {
      "displayName": "Joseph Wilson",
      "photoUrl": "",
      "userId": "10418926994387796219"
     },
     "user_tz": 240
    },
    "id": "LMo_BfyJW-kD"
   },
   "outputs": [],
   "source": [
    "### U-Net\n",
    "def conv_block(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )   \n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.conv_down_1 = conv_block(3, 8)\n",
    "        self.conv_down_2 = conv_block(8, 16)\n",
    "        self.conv_down_3 = conv_block(16, 32)\n",
    "        self.conv_down_4 = conv_block(32, 64)        \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
    "        \n",
    "        self.conv_up_3 = conv_block(32 + 64, 32)\n",
    "        self.conv_up_2 = conv_block(32 + 16, 16)\n",
    "        self.conv_up_1 = conv_block(16 + 8, 8)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(8, n_class, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1 = self.conv_down_1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.conv_down_2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.conv_down_3(x)\n",
    "        x = self.maxpool(conv3)   \n",
    "        \n",
    "        x = self.conv_down_4(x)\n",
    "        \n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "        \n",
    "        x = self.conv_up_3(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)       \n",
    "\n",
    "        x = self.conv_up_2(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "        \n",
    "        x = self.conv_up_1(x)\n",
    "        \n",
    "        out = self.conv_last(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4445,
     "status": "ok",
     "timestamp": 1619291787450,
     "user": {
      "displayName": "Joseph Wilson",
      "photoUrl": "",
      "userId": "10418926994387796219"
     },
     "user_tz": 240
    },
    "id": "qgb2pAIEWVTL",
    "outputId": "16c2ba9f-02a1-48b7-b9f9-416a1c148652"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (conv_down_1): Sequential(\n",
       "    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_down_2): Sequential(\n",
       "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_down_3): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_down_4): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "  (conv_up_3): Sequential(\n",
       "    (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_up_2): Sequential(\n",
       "    (0): Conv2d(48, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_up_1): Sequential(\n",
       "    (0): Conv2d(24, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_last): Conv2d(8, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UNet(3)\n",
    "model.load_state_dict(torch.load('/content/drive/MyDrive/EECS 545 Project/saved_model/JoeyModel3.pkl'))\n",
    "#model.load_state_dict(torch.load('/content/drive/MyDrive/EECS 545 Project/saved_model/model.pkl'))  ### remember to change the path\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4439,
     "status": "ok",
     "timestamp": 1619291787451,
     "user": {
      "displayName": "Joseph Wilson",
      "photoUrl": "",
      "userId": "10418926994387796219"
     },
     "user_tz": 240
    },
    "id": "jO1J6OakWr5X",
    "outputId": "ff75a1ff-6f5c-47cc-a872-e73e2177758c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (conv_down_1): Sequential(\n",
      "    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv_down_2): Sequential(\n",
      "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv_down_3): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv_down_4): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "  (conv_up_3): Sequential(\n",
      "    (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv_up_2): Sequential(\n",
      "    (0): Conv2d(48, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv_up_1): Sequential(\n",
      "    (0): Conv2d(24, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv_last): Conv2d(8, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "encoder = nn.Sequential(\n",
    "          model.conv_down_1,\n",
    "          model.conv_down_2,\n",
    "          model.conv_down_3,\n",
    "          model.conv_down_4,\n",
    "          model.maxpool\n",
    ")\n",
    "encoder.requires_grad = False\n",
    "\n",
    "encoder.to(device)\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 4527,
     "status": "ok",
     "timestamp": 1619291787545,
     "user": {
      "displayName": "Joseph Wilson",
      "photoUrl": "",
      "userId": "10418926994387796219"
     },
     "user_tz": 240
    },
    "id": "HZ0en49EXkm9"
   },
   "outputs": [],
   "source": [
    "class SmallDataLoader:\n",
    "  def __init__(self, BatchSize=16, TestPercent=0.1, data_loc=\"Weather\", img_size=224, dev=\"cuda\"):\n",
    "    self.train_names = []\n",
    "    self.train_labels = []\n",
    "    self.val_names = []\n",
    "    self.val_labels = []\n",
    "    self.test_names = []\n",
    "    self.test_labels = []\n",
    "\n",
    "    self.label_keys = {0: \"cloudy\", 1: \"foggy\", 2: \"rain\", 3: \"snow\", 4: \"sunny\"}\n",
    "    self.data_loc = os.path.join(os.getcwd(), data_loc)\n",
    "    self.batch_size = BatchSize\n",
    "    self.img_size = img_size\n",
    "    self.dev=dev\n",
    "\n",
    "    data_types = [\"cloudy\", \"foggy\", \"rain\", \"snow\", \"sunny\"]\n",
    "    splits = [\"Train\", \"Val\", \"Test\"]\n",
    "    for split in splits:\n",
    "      for i in range(5):\n",
    "        dtype = self.label_keys[i]\n",
    "        type_loc = os.path.join(data_loc, split, dtype)\n",
    "        files = os.listdir(type_loc)\n",
    "\n",
    "        if split == \"Train\":\n",
    "          self.train_labels += len(files) * [i]\n",
    "          self.train_names += files\n",
    "        elif split == \"Val\":\n",
    "          self.val_labels += len(files) * [i]\n",
    "          self.val_names += files\n",
    "        elif split == \"Test\":\n",
    "          self.test_labels += len(files) * [i]\n",
    "          self.test_names += files\n",
    "\n",
    "    # Shuffle data first\n",
    "    self.N_train = len(self.train_names) - len(self.train_names) % self.batch_size\n",
    "    self.N_val = len(self.val_names) - len(self.val_names) % self.batch_size\n",
    "    self.N_test = len(self.test_names) - len(self.test_names) % self.batch_size\n",
    "    self.shuffle_train()\n",
    "\n",
    "    self.iter_no = 0\n",
    "    self.val_no = 0\n",
    "\n",
    "    self.transform_dict = {\n",
    "        \"Train\": transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
    "        transforms.GaussianBlur(5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]),\n",
    "        \"Val\": transforms.Compose([\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    }\n",
    "\n",
    "  # index into file names, labels\n",
    "  def get_ind(self, index, dset=\"Train\"):\n",
    "    if dset == \"Train\":\n",
    "      fname = self.train_names[index]\n",
    "      label = self.train_labels[index]\n",
    "    elif dset == \"Val\":\n",
    "      fname = self.val_names[index]\n",
    "      label = self.val_labels[index]\n",
    "\n",
    "    label_name = self.label_keys[label]\n",
    "    img_loc = os.path.join(self.data_loc, dset, label_name, fname)\n",
    "    input_image = Image.open(img_loc).convert('RGB')\n",
    "    input_tensor = self.transform_dict[dset](input_image)\n",
    "\n",
    "    return input_tensor, label\n",
    "\n",
    "  # For training\n",
    "  def get_batch(self):\n",
    "    # End of Epoch\n",
    "    if self.iter_no + self.batch_size >= self.N_train:\n",
    "      self.iter_no = 0\n",
    "      return \"EOE\", None\n",
    "\n",
    "    batch_img = torch.zeros((self.batch_size, 3, self.img_size, self.img_size), device=self.dev)\n",
    "    batch_lab = torch.zeros((self.batch_size), device=self.dev, dtype=torch.long)\n",
    "    for i in range(self.batch_size):\n",
    "      input_tensor, label = self.get_ind(self.iter_no + i)\n",
    "      batch_img[i] = input_tensor\n",
    "      batch_lab[i] = label\n",
    "    self.iter_no += self.batch_size\n",
    "    return batch_img, batch_lab\n",
    "\n",
    "  def get_val(self):\n",
    "    if self.val_no + self.batch_size >= self.N_val:\n",
    "      self.val_no = 0\n",
    "      return \"EOE\", None\n",
    "\n",
    "    batch_img = torch.zeros((self.batch_size, 3, self.img_size, self.img_size), device=self.dev)\n",
    "    batch_lab = torch.zeros((self.batch_size), device=self.dev, dtype=torch.long)\n",
    "    for i in range(self.batch_size):\n",
    "      input_tensor, label = self.get_ind(self.val_no + i, dset=\"Val\")\n",
    "      batch_img[i] = input_tensor\n",
    "      batch_lab[i] = label\n",
    "    self.val_no += self.batch_size\n",
    "    return batch_img, batch_lab\n",
    "\n",
    "\n",
    "  def shuffle_train(self):\n",
    "    inds = np.random.choice(self.N_train, size=self.N_train, replace=False)\n",
    "    self.train_names = [self.train_names[i] for i in inds]\n",
    "    self.train_labels = [self.train_labels[i] for i in inds]\n",
    "    self.iter_no = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4832,
     "status": "ok",
     "timestamp": 1619291787853,
     "user": {
      "displayName": "Joseph Wilson",
      "photoUrl": "",
      "userId": "10418926994387796219"
     },
     "user_tz": 240
    },
    "id": "Qq6oYkFaXtNV",
    "outputId": "c816a82f-8c4c-4891-acc6-83b786304bfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 5])\n",
      "torch.Size([8, 64, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "dl = SmallDataLoader(BatchSize=batch_size, dev=device)\n",
    "\n",
    "# decoder = nn.Sequential(\n",
    "#     # Decreasing number of filters b/c too big for linear layers rn\n",
    "#     nn.Conv2d(64, 32, 3, padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(5, stride=2, padding=2),\n",
    "#     nn.Conv2d(32, 16, 3, padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(5, stride=2, padding=2),\n",
    "#     nn.Conv2d(16, 8, 3, padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(5, stride=2, padding=2),\n",
    "#     # Now using linear layers\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(8*14*14, 100),\n",
    "#     nn.Linear(100, 5)\n",
    "# )\n",
    "\n",
    "\n",
    "decoder = nn.Sequential(\n",
    "    # Decreasing number of filters b/c too big for linear layers rn\n",
    "    nn.MaxPool2d(5, stride=2, padding=2),\n",
    "    nn.MaxPool2d(5, stride=2, padding=2),\n",
    "    nn.MaxPool2d(5, stride=2, padding=2),\n",
    "    # Now using linear layers\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(64*14*14, 100),\n",
    "    nn.Linear(100, 5)\n",
    ")\n",
    "\n",
    "decoder.requires_grad = True\n",
    "\n",
    "# Test\n",
    "with torch.no_grad():\n",
    "  imgs, labels = dl.get_batch()\n",
    "  encodings = encoder(imgs)\n",
    "  decoder.to(device)\n",
    "  print(decoder(encodings).shape)\n",
    "  print(encodings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4827,
     "status": "ok",
     "timestamp": 1619291787854,
     "user": {
      "displayName": "Joseph Wilson",
      "photoUrl": "",
      "userId": "10418926994387796219"
     },
     "user_tz": 240
    },
    "id": "kb1oCBeYZjnw",
    "outputId": "1af4cd27-a9ee-4ba6-9008-04cb95f7f284"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=5, stride=2, padding=2, dilation=1, ceil_mode=False)\n",
      "    (1): MaxPool2d(kernel_size=5, stride=2, padding=2, dilation=1, ceil_mode=False)\n",
      "    (2): MaxPool2d(kernel_size=5, stride=2, padding=2, dilation=1, ceil_mode=False)\n",
      "    (3): Flatten(start_dim=1, end_dim=-1)\n",
      "    (4): Linear(in_features=12544, out_features=100, bias=True)\n",
      "    (5): Linear(in_features=100, out_features=5, bias=True)\n",
      "  )\n",
      ")\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "weather_model = nn.Sequential(\n",
    "    encoder,\n",
    "    decoder\n",
    ")\n",
    "\n",
    "# The model\n",
    "print(weather_model)\n",
    "# Making sure it is frozen\n",
    "print(weather_model[0].requires_grad)\n",
    "print(weather_model[1].requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5038,
     "status": "ok",
     "timestamp": 1619291788071,
     "user": {
      "displayName": "Joseph Wilson",
      "photoUrl": "",
      "userId": "10418926994387796219"
     },
     "user_tz": 240
    },
    "id": "a_in29IRckIb"
   },
   "outputs": [],
   "source": [
    "# Now try training it!\n",
    "def train_model(model, criterion, optimizer, scheduler, data_loader, num_epochs=10):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    train_hist = []\n",
    "    val_hist = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            data_loader.shuffle_train()\n",
    "            while True:\n",
    "                if phase == \"train\":\n",
    "                  inputs, labels = data_loader.get_batch()\n",
    "                else:\n",
    "                  inputs, labels = data_loader.get_val()\n",
    "                # End of epoch\n",
    "                if inputs == \"EOE\":\n",
    "                  break\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            if phase == \"train\":\n",
    "              epoch_loss = running_loss / data_loader.N_train\n",
    "              epoch_acc = running_corrects / data_loader.N_train\n",
    "            else:\n",
    "              epoch_loss = running_loss / data_loader.N_val\n",
    "              epoch_acc = running_corrects / data_loader.N_val\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            if phase == \"train\":\n",
    "              train_hist.append(epoch_acc)\n",
    "            else:\n",
    "              val_hist.append(epoch_acc)\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, train_hist, val_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 699851,
     "status": "ok",
     "timestamp": 1619292482889,
     "user": {
      "displayName": "Joseph Wilson",
      "photoUrl": "",
      "userId": "10418926994387796219"
     },
     "user_tz": 240
    },
    "id": "4pOFMfhecqaB",
    "outputId": "5bdffabb-6788-4bc5-9571-49a7fa7caf7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 76.0911 Acc: 0.2179\n",
      "val Loss: 73.1783 Acc: 0.1953\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 5.1821 Acc: 0.2621\n",
      "val Loss: 1.4567 Acc: 0.3438\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 1.4757 Acc: 0.3355\n",
      "val Loss: 1.4424 Acc: 0.3164\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 1.4434 Acc: 0.3494\n",
      "val Loss: 1.4407 Acc: 0.3242\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 1.4434 Acc: 0.3480\n",
      "val Loss: 1.4299 Acc: 0.3242\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 1.4466 Acc: 0.3457\n",
      "val Loss: 1.4300 Acc: 0.3242\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 1.4407 Acc: 0.3573\n",
      "val Loss: 1.4300 Acc: 0.3242\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 1.4478 Acc: 0.3462\n",
      "val Loss: 1.4300 Acc: 0.3242\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 1.4347 Acc: 0.3499\n",
      "val Loss: 1.4300 Acc: 0.3242\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 1.4525 Acc: 0.3415\n",
      "val Loss: 1.4300 Acc: 0.3242\n",
      "Training complete in 11m 35s\n",
      "Best val Acc: 0.343750\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Only the decoder is being optimized\n",
    "optimizer_ft = optim.Adam(weather_model[1].parameters(), lr=learning_rate)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=1, gamma=0.1)\n",
    "\n",
    "model, train_hist, val_hist = train_model(weather_model, criterion, optimizer_ft, exp_lr_scheduler, dl, num_epochs=num_epochs)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "JoeyTransferLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
